---
title: "Cap√≠tulo 6 ‚Äî Distribuciones de probabilidad (scipy.stats)"
---

[üöÄ Abrir este cap√≠tulo en Google Colab](https://colab.research.google.com/github/FraRafa/manual/blob/main/notebooks/06-distribuciones-de-probabilidad.ipynb){.btn .btn-success target="_blank"}

```{python}
#| include: false
# Setup interno (se ejecuta, pero no se muestra en HTML/PDF)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats

plt.rcParams["figure.figsize"] = (8, 4.5)
plt.rcParams["figure.dpi"] = 120
```

::: {.callout-note}
## Objetivos del cap√≠tulo

Vas a aprender a usar `scipy.stats` para:

- calcular **PMF/PDF**, **CDF** y **cuantiles** (`ppf`),
- graficar PMF/PDF y CDF de forma simple con `matplotlib`,
- simular variables aleatorias con `rvs` y comparar **muestra vs teor√≠a**,
- entender (por c√≥digo) qu√© significa ‚Äúpromedio acumulado‚Äù y por qu√© converge a la esperanza.
:::

::: {.column-margin}
<details>
<summary><strong>Glosario</strong></summary>

- **PMF**: *probability mass function* (masa) ‚Üí discretas (`pmf`).
- **PDF**: *probability density function* (densidad) ‚Üí continuas (`pdf`).
- **CDF**: *cumulative distribution function* (acumulada) ‚Üí `cdf`.
- **PPF**: *percent point function* (cuantil) ‚Üí inversa de la CDF (`ppf`).
- **rvs**: *random variates* ‚Üí simular una muestra (`rvs`).
- **loc / scale**: par√°metros est√°ndar de `scipy` (inicio y escala).
</details>
:::

---

## 1. `scipy.stats`: el patr√≥n de uso

En `scipy.stats`, muchas distribuciones siguen este patr√≥n:

- Discretas: `pmf(x, ...)` y `cdf(x, ...)`
- Continuas: `pdf(x, ...)` y `cdf(x, ...)`
- Cuantiles: `ppf(q, ...)` (por ejemplo, `q=0.95`)
- Simulaci√≥n: `rvs(..., size=n, random_state=...)`

::: {.callout-note}
### Sintaxis (plantilla)

- Discreta: `stats.binom.pmf(x, n, p)` / `stats.binom.cdf(x, n, p)`
- Continua: `stats.norm.pdf(x, mu, sigma)` / `stats.norm.cdf(x, mu, sigma)`
- Cuantil: `stats.norm.ppf(0.975, mu, sigma)`
- Simular: `stats.norm.rvs(mu, sigma, size=1000, random_state=123)`
:::

---

## 2. Distribuciones discretas

### 2.1 Uniforme discreta (`randint`)

```{python}
# Par√°metros
a = 1  # primer valor
b = 6  # √∫ltimo valor

# Valores de X (para tabla) y valores para gr√°fica CDF
x = np.arange(a, b + 1)
xg = np.arange(a - 1, b + 2)

# PMF y CDF
fx = stats.randint.pmf(x, a, b + 1)
Fx = stats.randint.cdf(x, a, b + 1)
Fxg = stats.randint.cdf(xg, a, b + 1)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist
```

::: {.callout-note}
### Sintaxis clave (`randint`)

- En `scipy`, `randint(a, b+1)` representa enteros en **[a, b]**.
- Por eso ver√°s `b+1` en la funci√≥n.
:::

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.title(f"PMF ‚Äî Uniforme discreta: X ~ U{{{a},{b}}}")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, where="post", color="black")
plt.title(f"CDF ‚Äî Uniforme discreta: X ~ U{{{a},{b}}}")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

---

### 2.2 Bernoulli (`bernoulli`)

```{python}
x = [0, 1]
xg = np.linspace(-0.1, 1.1, num=1000)

p = 0.2

fx = stats.bernoulli.pmf(x, p)
Fx = stats.bernoulli.cdf(x, p)
Fxg = stats.bernoulli.cdf(xg, p)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist
```

::: {.callout-note}
### Sintaxis clave (Bernoulli)

- `x` solo puede ser 0 o 1.
- `p` es la probabilidad de √©xito (`X=1`).
:::

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.xticks(x, ["0", "1"])
plt.title(f"PMF ‚Äî Bernoulli: X ~ Be({p})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, color="black")
plt.title(f"CDF ‚Äî Bernoulli: X ~ Be({p})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

---

### 2.3 Binomial (`binom`)

Ejemplo t√≠pico: *n* ensayos Bernoulli independientes con probabilidad de √©xito *p*.

```{python}
x = np.linspace(0, 10, num=11)
xg = np.linspace(-0.5, 10.1, num=1000)

p = 0.2
n = 10

fx = stats.binom.pmf(x, n, p)
Fx = stats.binom.cdf(x, n, p)
Fxg = stats.binom.cdf(xg, n, p)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist.head()
```

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.title(f"PMF ‚Äî Binomial: X ~ Bn({n},{p})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, color="black")
plt.title(f"CDF ‚Äî Binomial: X ~ Bn({n},{p})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Probabilidad puntual (ejemplo): `P(X=2)` con `n=10`, `p=0.2`.

```{python}
stats.binom.pmf(2, 10, 0.2)
```

---

### 2.4 Poisson (`poisson`)

```{python}
x = np.linspace(0, 15, num=16)
xg = np.linspace(-0.5, 15, num=1500)

plambda = 4

fx = stats.poisson.pmf(x, plambda)
Fx = stats.poisson.cdf(x, plambda)
Fxg = stats.poisson.cdf(xg, plambda)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist.head()
```

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.title(f"PMF ‚Äî Poisson: X ~ Poi({plambda})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, color="black")
plt.title(f"CDF ‚Äî Poisson: X ~ Poi({plambda})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

---

### 2.5 Geom√©trica (`geom`)

En `scipy.stats.geom`, el soporte empieza en 1, pero es com√∫n graficar desde 0 para ver que `P(X=0)=0`.

```{python}
x = np.linspace(0, 15, num=16)
xg = np.linspace(-0.5, 15, num=1500)

p = 0.4

fx = stats.geom.pmf(x, p)
Fx = stats.geom.cdf(x, p)
Fxg = stats.geom.cdf(xg, p)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist.head()
```

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.title(f"PMF ‚Äî Geom√©trica: X ~ Ge({p})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, color="black")
plt.title(f"CDF ‚Äî Geom√©trica: X ~ Ge({p})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

---

### 2.6 Binomial negativa (`nbinom`)

```{python}
x = np.linspace(0, 20, num=21)
xg = np.linspace(-0.5, 20, num=2000)

p = 0.4
r = 3

fx = stats.nbinom.pmf(x, r, p)
Fx = stats.nbinom.cdf(x, r, p)
Fxg = stats.nbinom.cdf(xg, r, p)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist.head()
```

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.title(f"PMF ‚Äî Binomial negativa: X ~ BN({r},{p})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, color="black")
plt.title(f"CDF ‚Äî Binomial negativa: X ~ BN({r},{p})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

---

### 2.7 Hipergeom√©trica (`hypergeom`)

```{python}
x = np.linspace(0, 20, num=21)
xg = np.linspace(0, 20, num=21)

N = 100  # poblaci√≥n
m = 80   # √©xitos en la poblaci√≥n
n = 20   # muestra

fx = stats.hypergeom.pmf(x, N, m, n)
Fx = stats.hypergeom.cdf(x, N, m, n)
Fxg = stats.hypergeom.cdf(xg, N, m, n)

tabla_dist = pd.DataFrame({"x": x, "PMF": fx, "CDF": Fx})
tabla_dist.head()
```

```{python}
plt.bar(x, fx, color="0.6", edgecolor="black")
plt.title(f"PMF ‚Äî Hipergeom√©trica: X ~ H({N},{m},{n})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.step(xg, Fxg, color="black")
plt.title(f"CDF ‚Äî Hipergeom√©trica: X ~ H({N},{m},{n})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

---

## 3. Distribuciones continuas

### 3.1 Uniforme continua (`uniform`)

```{python}
x = np.linspace(-4, 4, num=200)
xt = np.linspace(-4, 4, num=9)

alpha = -3
beta = 3

fx = stats.uniform.pdf(x, alpha, beta - alpha)
Fx = stats.uniform.cdf(x, alpha, beta - alpha)
Fxt = stats.uniform.cdf(xt, alpha, beta - alpha)

tabla_dist = pd.DataFrame({"x": xt, "CDF": Fxt})
tabla_dist
```

::: {.callout-note}
### Sintaxis clave (uniform)

En `scipy`:

- `loc = alpha`
- `scale = beta - alpha`
:::

```{python}
plt.plot(x, fx, linestyle="-", color="black")
plt.title(f"PDF ‚Äî Uniforme continua: X ~ U({alpha},{beta})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(x, Fx, linestyle="-", color="black")
plt.title(f"CDF ‚Äî Uniforme continua: X ~ U({alpha},{beta})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantiles (ejemplo): intervalo central 95%.

```{python}
q025 = stats.uniform.ppf(0.025, alpha, beta - alpha)
q975 = stats.uniform.ppf(0.975, alpha, beta - alpha)
q025, q975
```

---

### 3.2 Normal (`norm`)

```{python}
x = np.linspace(-5, 15, num=100)
xt = np.linspace(-5, 15, num=11)

mu = 5
sigma = 2

fx = stats.norm.pdf(x, mu, sigma)
Fx = stats.norm.cdf(x, mu, sigma)
Fxt = stats.norm.cdf(xt, mu, sigma)

tabla_dist = pd.DataFrame({"x": xt, "CDF": Fxt})
tabla_dist
```

```{python}
plt.plot(x, fx, linestyle="-", color="black")
plt.title(f"PDF ‚Äî Normal: X ~ N({mu},{sigma})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(x, Fx, linestyle="-", color="black")
plt.title(f"CDF ‚Äî Normal: X ~ N({mu},{sigma})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantiles (intervalo central 95%):

```{python}
q025 = stats.norm.ppf(0.025, mu, sigma)
q975 = stats.norm.ppf(0.975, mu, sigma)
q025, q975
```

Ejemplo de probabilidad: si `X ~ N(4, 9)`, calcula `P(2 < X ‚â§ 6)`.

```{python}
stats.norm.cdf(6, 4, 3) - stats.norm.cdf(2, 4, 3)
```

---

### 3.3 Normal est√°ndar: estandarizaci√≥n

Aqu√≠ hacemos dos cosas:

1) estandarizar valores: `z = (x - mu)/sigma`  
2) usar la normal est√°ndar `N(0,1)`.

```{python}
x = np.linspace(-5, 15, num=100)
xt = np.linspace(-5, 15, num=11)

mu = 5
sigma = 2

z = (x - mu) / sigma
zt = (xt - mu) / sigma

fz = stats.norm.pdf(z)
Fz = stats.norm.cdf(z)
Fzt = stats.norm.cdf(zt)

tabla_dist = pd.DataFrame({"z": zt, "CDF": Fzt})
tabla_dist
```

```{python}
plt.plot(z, fz, linestyle="-", color="black")
plt.title("PDF ‚Äî Normal est√°ndar: Z ~ N(0,1)")
plt.xlabel("z")
plt.ylabel("œÜ(z)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(z, Fz, linestyle="-", color="black")
plt.title("CDF ‚Äî Normal est√°ndar: Z ~ N(0,1)")
plt.xlabel("z")
plt.ylabel("Œ¶(z)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantiles de la normal est√°ndar (95% central):

```{python}
stats.norm.ppf(0.025), stats.norm.ppf(0.975)
```

---

### 3.4 Chi-cuadrado (`chi2`)

```{python}
w = np.linspace(0, 15, num=100)
wt = np.linspace(0, 15, num=16)

m = 5

fw = stats.chi2.pdf(w, m)
Fw = stats.chi2.cdf(w, m)
Fwt = stats.chi2.cdf(wt, m)

tabla_dist = pd.DataFrame({"w": wt, "CDF": Fwt})
tabla_dist.head()
```

```{python}
plt.plot(w, fw, linestyle="-", color="black")
plt.title(rf"PDF ‚Äî Chi-cuadrado: W ~ $\chi^2$({m})")
plt.xlabel("w")
plt.ylabel("f(w)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(w, Fw, linestyle="-", color="black")
plt.title(rf"CDF ‚Äî Chi-cuadrado: W ~ $\chi^2$({m})")
plt.xlabel("w")
plt.ylabel("F(w)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantil 0.95:

```{python}
stats.chi2.ppf(0.95, m)
```

---

### 3.5 t de Student (`t`)

```{python}
v = np.linspace(-5, 5, num=100)
vt = np.linspace(-5, 5, num=11)

m = 5

fv = stats.t.pdf(v, m)
Fv = stats.t.cdf(v, m)
Fvt = stats.t.cdf(vt, m)

tabla_dist = pd.DataFrame({"v": vt, "CDF": Fvt})
tabla_dist
```

```{python}
plt.plot(v, fv, linestyle="-", color="black")
plt.title(f"PDF ‚Äî t de Student: V ~ t({m})")
plt.xlabel("v")
plt.ylabel("f(v)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(v, Fv, linestyle="-", color="black")
plt.title(f"CDF ‚Äî t de Student: V ~ t({m})")
plt.xlabel("v")
plt.ylabel("F(v)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantiles 0.025 y 0.975:

```{python}
stats.t.ppf(0.025, m), stats.t.ppf(0.975, m)
```

---

### 3.6 F de Fisher (`f`)

```{python}
r = np.linspace(0, 15, num=100)
rt = np.linspace(0, 15, num=16)

m1 = 5
m2 = 3

fr = stats.f.pdf(r, m1, m2)
Fr = stats.f.cdf(r, m1, m2)
Frt = stats.f.cdf(rt, m1, m2)

tabla_dist = pd.DataFrame({"r": rt, "CDF": Frt})
tabla_dist.head()
```

```{python}
plt.plot(r, fr, linestyle="-", color="black")
plt.title(rf"PDF ‚Äî F: R ~ F({m1},{m2})")
plt.xlabel("r")
plt.ylabel("f(r)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(r, Fr, linestyle="-", color="black")
plt.title(rf"CDF ‚Äî F: R ~ F({m1},{m2})")
plt.xlabel("r")
plt.ylabel("F(r)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantil 0.95:

```{python}
stats.f.ppf(0.95, m1, m2)
```

---

### 3.7 Exponencial (`expon`)

```{python}
x = np.linspace(-0.5, 6, num=150)
xt = np.linspace(-0.5, 6, num=9)

plambda = 1

fx = stats.expon.pdf(x, scale=1 / plambda)
Fx = stats.expon.cdf(x, scale=1 / plambda)
Fxt = stats.expon.cdf(xt, scale=1 / plambda)

tabla_dist = pd.DataFrame({"x": xt, "CDF": Fxt})
tabla_dist
```

::: {.callout-note}
### Sintaxis clave (expon)

Si t√∫ trabajas con tasa `Œª`, en `scipy` se usa:

- `scale = 1/Œª`
:::

```{python}
plt.plot(x, fx, linestyle="-", color="black")
plt.title(f"PDF ‚Äî Exponencial: X ~ Exp({plambda})")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

```{python}
plt.plot(x, Fx, linestyle="-", color="black")
plt.title(f"CDF ‚Äî Exponencial: X ~ Exp({plambda})")
plt.xlabel("x")
plt.ylabel("F(x)")
plt.grid(alpha=0.4)
plt.show()
plt.close()
```

Cuantil 0.95:

```{python}
stats.expon.ppf(0.95, scale=1 / plambda)
```

---

## 4. Simulaci√≥n (muestra vs teor√≠a)

La simulaci√≥n tiene dos ideas √∫tiles:

1) comparar ‚Äúlo que sali√≥‚Äù (frecuencia/histograma) con ‚Äúla teor√≠a‚Äù (PMF/PDF),  
2) ver c√≥mo el **promedio acumulado** converge a la esperanza te√≥rica.

---

### 4.1 Bernoulli simulada

```{python}
semilla = None  # None -> resultados diferentes cada ejecuci√≥n
ns = 1000
p = 0.5

muestra = stats.bernoulli.rvs(p, size=ns, random_state=semilla)

# Frecuencias
valores, freq_abs = np.unique(muestra, return_counts=True)
freq_rel = freq_abs / ns

# PMF te√≥rica
pmft = stats.bernoulli.pmf(valores, p)

# Comparaci√≥n: muestra vs teor√≠a
plt.bar(valores - 0.15, freq_rel, width=0.2, color="blue", label="Muestra")
plt.bar(valores + 0.15, pmft, width=0.2, color="red", label="Teor√≠a")
for xx, yy in zip(valores - 0.15, freq_rel):
    plt.text(xx, yy + 0.005, f"{yy:.3f}", ha="center", va="bottom")
plt.xlabel("Valor")
plt.ylabel("Probabilidad / Frecuencia relativa")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Frecuencia relativa vs PMF te√≥rica")
plt.show()
plt.close()

# Promedio acumulado
cum_ns = np.arange(1, ns + 1)
plt.plot(cum_ns, muestra.cumsum() / cum_ns, label="Promedio acumulado")
plt.axhline(y=p, color="red", label="Esperanza te√≥rica")
plt.xlabel("N√∫mero de simulaciones")
plt.ylabel("Promedio acumulado de √©xitos (X=1)")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Promedio acumulado vs Esperanza te√≥rica")
plt.show()
plt.close()
```

---

### 4.2 Uniforme discreta simulada

```{python}
semilla = None
ns = 1000
a, b = 1, 6

muestra = stats.randint.rvs(a, b + 1, size=ns, random_state=semilla)

valores, freq_abs = np.unique(muestra, return_counts=True)
freq_rel = freq_abs / ns

pmft = stats.randint.pmf(valores, a, b + 1)

plt.bar(valores - 0.15, freq_rel, width=0.2, color="blue", label="Muestra")
plt.bar(valores + 0.15, pmft, width=0.2, color="red", label="Teor√≠a")
for xx, yy in zip(valores - 0.15, freq_rel):
    plt.text(xx, yy + 0.005, f"{yy:.3f}", ha="center", va="bottom")
plt.xlabel("Valor")
plt.ylabel("Probabilidad / Frecuencia relativa")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Frecuencia relativa vs PMF te√≥rica")
plt.show()
plt.close()

cum_ns = np.arange(1, ns + 1)
plt.plot(cum_ns, muestra.cumsum() / cum_ns, label="Promedio acumulado")
plt.axhline(y=(a + b) / 2, color="red", label="Esperanza te√≥rica")
plt.xlabel("N√∫mero de simulaciones")
plt.ylabel("Promedio acumulado de valores de X")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Promedio acumulado vs Esperanza te√≥rica")
plt.show()
plt.close()
```

---

### 4.3 Normal simulada

```{python}
semilla = None
ns = 1000
mu, sigma = 0, 1

muestra = stats.norm.rvs(mu, sigma, size=ns, random_state=semilla)

lim = max(abs(muestra.min()), abs(muestra.max()))
x = np.linspace(-lim, lim, num=100)
pdft = stats.norm.pdf(x, mu, sigma)

plt.hist(muestra, bins=10, density=True, edgecolor="black", color="blue", alpha=0.5, label="Muestra")
plt.plot(x, pdft, color="red", linewidth=3, label="Teor√≠a")
plt.xlabel("X")
plt.ylabel("Densidad")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Histograma vs PDF te√≥rica")
plt.show()
plt.close()

cum_ns = np.arange(1, ns + 1)
plt.plot(cum_ns, muestra.cumsum() / cum_ns, label="Promedio acumulado")
plt.axhline(y=mu, color="red", label="Esperanza te√≥rica")
plt.xlabel("N√∫mero de simulaciones")
plt.ylabel("Promedio acumulado de valores de X")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Promedio acumulado vs Esperanza te√≥rica")
plt.show()
plt.close()
```

---

### 4.4 Chi-cuadrado simulada (por partes)

La chi-cuadrado puede verse como suma de cuadrados de normales est√°ndar.

```{python}
semilla = None
ns = 1000
m = 5

sim_partes = True
if sim_partes:
    sim_var2 = []
    for i in range(1, m + 1):
        semilla2 = None if semilla is None else semilla + i
        sim_var = stats.norm.rvs(size=ns, random_state=semilla2)  # Z ~ N(0,1)
        sim_var2.append(sim_var**2)
    muestra = sum(sim_var2)
else:
    muestra = stats.chi2.rvs(m, size=ns, random_state=semilla)

# PDF te√≥rica
lim = max(abs(muestra.min()), abs(muestra.max()))
x = np.linspace(0, lim, num=200)
pdft = stats.chi2.pdf(x, m)

plt.hist(muestra, bins=12, density=True, edgecolor="black", color="blue", alpha=0.5, label="Muestra")
plt.plot(x, pdft, color="red", linewidth=3, label="Teor√≠a")
plt.xlabel("X")
plt.ylabel("Densidad")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Histograma vs PDF te√≥rica")
plt.show()
plt.close()

cum_ns = np.arange(1, ns + 1)
plt.plot(cum_ns, muestra.cumsum() / cum_ns, label="Promedio acumulado")
plt.axhline(y=m, color="red", label="Esperanza te√≥rica")
plt.xlabel("N√∫mero de simulaciones")
plt.ylabel("Promedio acumulado de valores de X")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Promedio acumulado vs Esperanza te√≥rica")
plt.show()
plt.close()
```

---

### 4.5 t de Student simulada (por construcci√≥n)

Una forma de construir una t es: `Z / sqrt(W/m)` con `Z ~ N(0,1)` y `W ~ chi^2(m)` independientes.

```{python}
semilla = None
ns = 1000
m = 5

sim_partes = True
if sim_partes:
    semilla2 = None if semilla is None else semilla + 1
    sim_var_Z = stats.norm.rvs(size=ns, random_state=semilla)
    sim_var_W = stats.chi2.rvs(m, size=ns, random_state=semilla2)
    muestra = sim_var_Z / np.sqrt(sim_var_W / m)
else:
    muestra = stats.t.rvs(m, size=ns, random_state=semilla)

# PDF te√≥rica
lim = max(abs(muestra.min()), abs(muestra.max()))
x = np.linspace(-lim, lim, num=200)
pdft = stats.t.pdf(x, m)

plt.hist(muestra, bins=20, density=True, edgecolor="black", color="blue", alpha=0.5, label="Muestra")
plt.plot(x, pdft, color="red", linewidth=3, label="Teor√≠a")
plt.xlabel("X")
plt.ylabel("Densidad")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Histograma vs PDF te√≥rica")
plt.show()
plt.close()

cum_ns = np.arange(1, ns + 1)
plt.plot(cum_ns, muestra.cumsum() / cum_ns, label="Promedio acumulado")
plt.axhline(y=0, color="red", label="Esperanza te√≥rica")
plt.xlabel("N√∫mero de simulaciones")
plt.ylabel("Promedio acumulado de valores de X")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Promedio acumulado vs Esperanza te√≥rica")
plt.show()
plt.close()
```

---

### 4.6 F de Fisher simulada (por construcci√≥n)

Construcci√≥n t√≠pica:

\[
R = (W_1/m_1) / (W_2/m_2),
\]
donde `W1 ~ chi^2(m1)` y `W2 ~ chi^2(m2)` independientes.

```{python}
semilla = None
ns = 1000
m1, m2 = 5, 3

sim_partes = True
if sim_partes:
    semilla2 = None if semilla is None else semilla + 1
    sim_var_W1 = stats.chi2.rvs(m1, size=ns, random_state=semilla)
    sim_var_W2 = stats.chi2.rvs(m2, size=ns, random_state=semilla2)
    muestra = (sim_var_W1 / m1) / (sim_var_W2 / m2)
else:
    muestra = stats.f.rvs(m1, m2, size=ns, random_state=semilla)

# PDF te√≥rica
lim = np.quantile(muestra, 0.99)  # evita que un extremo gigante "rompa" la gr√°fica
x = np.linspace(0, lim, num=200)
pdft = stats.f.pdf(x, m1, m2)

plt.hist(muestra, bins=30, density=True, edgecolor="black", color="blue", alpha=0.5, label="Muestra")
plt.plot(x, pdft, color="red", linewidth=3, label="Teor√≠a")
plt.xlabel("X")
plt.ylabel("Densidad")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Histograma vs PDF te√≥rica")
plt.show()
plt.close()

cum_ns = np.arange(1, ns + 1)
plt.plot(cum_ns, muestra.cumsum() / cum_ns, label="Promedio acumulado")
plt.axhline(y=m2 / (m2 - 2), color="red", label="Esperanza te√≥rica")
plt.xlabel("N√∫mero de simulaciones")
plt.ylabel("Promedio acumulado de valores de X")
plt.grid(alpha=0.4)
plt.legend(loc="upper center", bbox_to_anchor=(0.5, -0.12))
plt.title("Promedio acumulado vs Esperanza te√≥rica")
plt.show()
plt.close()
```

---

## Ejercicios propuestos

1) **Binomial (PMF y CDF)**  
   Para `X ~ Bn(10, 0.2)`, calcula `P(X=2)` y `P(X‚â§2)`.

   **Respuesta esperada:** dos n√∫meros en (0, 1).

2) **Cuantiles (normal)**  
   Para `X ~ N(5,2)`, calcula el intervalo central del 95% usando `ppf(0.025)` y `ppf(0.975)`.

   **Respuesta esperada:** dos valores (l√≠mite inferior y superior).

3) **Normal est√°ndar**  
   Estandariza `x=9` si `X ~ N(5,2)` y calcula `P(X‚â§9)` usando `Œ¶(z)` (CDF est√°ndar).

   **Respuesta esperada:** un valor cercano a `0.977` (aprox.).

4) **Simulaci√≥n Bernoulli**  
   Simula `ns=5000` con `p=0.3` y grafica el promedio acumulado.

   **Respuesta esperada:** el promedio acumulado se acerca a `0.3`.

5) **Exponencial**  
   Con `Œª=1`, calcula el cuantil 0.95 con `ppf`.

   **Respuesta esperada:** un valor cercano a `‚âà 3`.

6) **F de Fisher**  
   Para `F(5,3)`, calcula el cuantil 0.95.

   **Respuesta esperada:** un n√∫mero positivo mayor que 1.

---

::: {.content-visible when-format="pdf"}
## Glosario (para Colab)

- **PMF/PDF/CDF**: masa / densidad / acumulada.
- **PPF**: cuantil (inversa de la CDF).
- **rvs**: simulaci√≥n (muestra aleatoria).
- **loc/scale**: par√°metros est√°ndar de `scipy`.
:::
